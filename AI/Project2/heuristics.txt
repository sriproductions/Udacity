Heuristic 1: Return ratio of player moves to opponent moves
Intuition: This simple heuristic is based on the notion that the number of moves of a player provides more player options and improves chances of player win -- chances of winning directly proportional to player options.  Also, chances of player winning is inversely proportional number of opponent's choices.  This heuristic performs about the same as the improved ID heuristic on the average.  This is likely because the overall intuition behind the score is the same, albeit the computation of the score is different.

Heuristic 2: Return the move that gives the maximum choices to player, and minimum choices to opponent, one move ahead.  This is similar to the improved algorithm ID_improved, except it looks one move further ahead. The logic is that the further moves ahead that we examine the chances of winning, the higher the chances of winning. This assumes that the game is not pathological, in the sense that examining further into the future does not decrease the chances of winning, which seems to be true for isolation. The score computed one move ahead is the same as ID_improved, i.e., it picks the score that maximizes the difference between the choices for the player and the opponent.
	  As a first cut, the score calulated was as follows: for a given player move, score is the maximum of "number of choices for player in next move - number of choices of player for the opponent". This performed rather poorly compared to the improved_ID heuristic. The reason for this is that looking further ahead and ignoring immediate moves ignores the opponents next move, so we may be evaluating the score associated with a search tree of low probability.
	  So the value of the current set of moves available to the player was incorporated into the score as follows: "(number of current choices for player * number of choices for player in next move given an opponent move) - number of choices for opponent given an opponent move". This significantly improved the performance of the algorithm.

Heuristic 3: This heuristic is based on the "Game Tree search: Min/Max approximation" paper by Ronald Rivest.
This is a simplification of the technique described in the paper, because we only expand the tree rooted at each examined node for a depth of 1, and then compute the penalties for that sub tree.  This reduces the effectiveness of the algorithm, which back-propagates the penalties all the way back to the root of the subtree for arbitrary depths. The actual algorithm cannot be implemented for this project because it requires a different code structure not allowed by the project implementation framework. Specifically, to implement the algorithm described in the paper,  we need to keep track of the weights, penalties and shortest subtree path to the leaf node for each node in the tree.
	Instead, the score calculated goes one move ahead for the player, i.e., the lowest penalty player->opponent->player,  and calculates the choices with the least penalty and returns the inverse of the penalty as the score. Note that the limitation here is that we do not look at all the global choices for expansion of a node as required by the algorithm in the paper, but only the choices from the current board state ignoring the history of the game upto the current board. A faithful implementation of the algorithm in the paper would require that the penalties be recalculated all the way up to the root of the tree, affecting the penalties at all non-terminal nodes yet to be expanded.
